{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9a934be",
   "metadata": {},
   "source": [
    "# 決定木"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995e556b",
   "metadata": {},
   "source": [
    "## 参考資料"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9ba767",
   "metadata": {},
   "source": [
    "* https://www.kaggle.com/code/antonoof/decisiontree-numpy-simple-code\n",
    "* https://qiita.com/3000manJPY/items/ef7495960f472ec14377\n",
    "* https://zenn.dev/mi_01_24fu/articles/regression-tree#%E5%90%84%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3%E3%81%A7sse%E3%82%92%E7%AE%97%E5%87%BA%E3%81%97%E3%81%9F%E7%B5%90%E6%9E%9C%E3%80%81%E6%9C%80%E5%B0%8Fsse%E3%81%8C%E5%88%86%E3%81%8B%E3%81%A3%E3%81%9F%E3%80%81%E3%81%98%E3%82%83%E3%81%82%E3%81%A9%E3%81%86%E3%81%99%E3%82%8B%E3%81%AE%EF%BC%9F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24a88bd",
   "metadata": {},
   "source": [
    "## 理論"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a28c46a",
   "metadata": {},
   "source": [
    "決定木とは分類や数値予測(回帰)を行う教師あり機械学習手法の一つ。\n",
    "分類木と回帰木をまとめて決定木と呼ぶ。 <br><br>\n",
    "分類木 : 与えられた特徴量に基づき、対象データがどのカテゴリに属するか判断するモデル <br>\n",
    "ex) メールを「スパム」「非スパム」に分類する。 <br><br>\n",
    "回帰木 : 連続的な値の予測に特化したモデル <br>\n",
    "ex) 過去の地球温暖化のデータを利用して将来の気温上昇を予測する。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121d851d",
   "metadata": {},
   "source": [
    "分岐させる時の閾値は人間が決めるのではなく、自動で最適化する。\n",
    "そのとき、データの持つ特徴の中で集められたデータを一番よく分割する特徴とその閾値の組を選ぶことが肝になる。\n",
    "この組を選び出すのによく使われているのが「エントロピー」と「ジニ不純度」である。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdb359c",
   "metadata": {},
   "source": [
    "### エントロピー"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debba441",
   "metadata": {},
   "source": [
    "定義"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0defe6b6",
   "metadata": {},
   "source": [
    "$$ H = - \\sum_{i = 1}^n p_i \\log p_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6d64a5",
   "metadata": {},
   "source": [
    "$ p_i $はクラス$ i $に属する確率(割合)を表すので、$ p_i = \\dfrac{n_i}{N} $と書くことができる。 <br>\n",
    "$ \\log $の底はなんでも良いが、クラス数$ n $にしておくと、エントロピーの最大値が$ 1 $となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b7f21a",
   "metadata": {},
   "source": [
    "エントロピーはデータの不純度が大きいほど大きくなり、データの不純度が小さいほど小さくなる。 <br>\n",
    "したがってデータの不純度度合いをエントロピーを用いて数値化できる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec58a98",
   "metadata": {},
   "source": [
    "では、どのようにしてデータの分割の良し悪しを判断するのだろうか。 <br>\n",
    "そこで利得(gain)をエントロピーを用いる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04e6acd",
   "metadata": {},
   "source": [
    "$$ \\Delta H(t) = H(t_B) - \\sum_{i = 1}^b w_i H_i(t_{Ai}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc42cb1",
   "metadata": {},
   "source": [
    "$ b $ : 分岐(ブランチ)の数 <br>\n",
    "$ t_B $ : 分岐前のデータ　<br>\n",
    "$ t_A $ : 分岐後のデータ <br>\n",
    "$ w_i $ : 重み(分岐前に対するデータの量の割合)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30369bd4",
   "metadata": {},
   "source": [
    "$$ \\text{(分岐前のエントロピー)} - \\sum \\text{重み} \\times \\text{(分岐後のエントロピー)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9903aa",
   "metadata": {},
   "source": [
    "分岐した時にうまく不純度が小さくなっていれば、右辺の分岐後のエントロピーが小さくなり、利得が大きくなる。 <br>\n",
    "つまり、この式の計算結果が最大となるような特徴と閾値の組が不純度を最小にする組であるとわかる。 <br>\n",
    "この分割指標を用いて決定木を構築していくアルゴリズムがC4.5である。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eac8eb",
   "metadata": {},
   "source": [
    "### ジニ不純度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b7eba8",
   "metadata": {},
   "source": [
    "定義"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f246078c",
   "metadata": {},
   "source": [
    "$$ G = 1 - \\sum_{i = 1}^n p_i^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e26c64",
   "metadata": {},
   "source": [
    "ジニ不純度もエントロピーと同様、データの不純度が大きいほど値が大きくなり、データが不純度が小さいほど値が小さくなる。<br>\n",
    "また、不純度が最も低ければジニ不純度の値は$ 0 $、不純度が大きくなるとジニ不純度の値が$ 1 $に近づく。(最大でも$ 1 - \\dfrac{1}{n}$なので$ 1 $は取りえない)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dbf816",
   "metadata": {},
   "source": [
    "エントロピーと同様に利得を計算することで、データの分割の良し悪しを判断する。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c135a17a",
   "metadata": {},
   "source": [
    "$$ \\Delta G = G(t_B) - w_L G(t_L) - w_R G(t_R) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4df85d",
   "metadata": {},
   "source": [
    "$ t_B $ : 分岐前のノード <br>\n",
    "$ t_L, t_R $ : 分岐後の左(右)ノード"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1897e77a",
   "metadata": {},
   "source": [
    "不純度がうまく分岐によって低くなると、利得は大きくなる。 <br>\n",
    "よって、ジニ不純度の場合も値を最大にする特徴と閾値の組が、最も不純度を抑える組である。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c26891",
   "metadata": {},
   "source": [
    "この分割指標を用いて決定木を構築していくアルゴリズムがCARTである。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a820a504",
   "metadata": {},
   "source": [
    "## 実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "106158f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9a94be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72750245",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
